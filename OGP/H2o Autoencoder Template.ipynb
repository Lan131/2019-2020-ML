{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf nightly only version of tf 2.0 with tensorboard support\n",
    "#!pip install tf-nightly --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data from https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open tensorboard\n",
    "#!python -m tensorboard.main --logdir=/path/to/logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h2o\n",
    "import pandas_profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "from h2o.estimators.deeplearning import H2OAutoEncoderEstimator, H2ODeepLearningEstimator\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "SEED=42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    mean_absolute_error = history['mean_absolute_error']\n",
    "   \n",
    "    loss = history['loss']\n",
    "    \n",
    "    x = range(1, len(mean_absolute_error) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, mean_absolute_error, 'r', label='Training error')\n",
    "    plt.title('Loss and accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile = ProfileReport(df, title='Pandas Profiling Report', html={'style':{'full_width':True}},plot ={'histogram':{'bayesian_blocks_bins': False}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile.to_file(output_file=\"credit_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode)\n",
      "  Starting server from C:\\Users\\Michael Lanier\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\MICHAE~1\\AppData\\Local\\Temp\\tmp0f_1vfjw\n",
      "  JVM stdout: C:\\Users\\MICHAE~1\\AppData\\Local\\Temp\\tmp0f_1vfjw\\h2o_Michael_Lanier_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\MICHAE~1\\AppData\\Local\\Temp\\tmp0f_1vfjw\\h2o_Michael_Lanier_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Chicago</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.28.0.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>27 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_Michael_Lanier_3tlytz</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>19.17 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>{'http': None, 'https': None}</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.4 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       America/Chicago\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.28.0.3\n",
       "H2O cluster version age:    27 days\n",
       "H2O cluster name:           H2O_from_python_Michael_Lanier_3tlytz\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    19.17 Gb\n",
       "H2O cluster total cores:    12\n",
       "H2O cluster allowed cores:  12\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:       {'http': None, 'https': None}\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python version:             3.7.4 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "h2o.init(min_mem_size='20G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "data=h2o.import_file(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  Time</th><th style=\"text-align: right;\">       V1</th><th style=\"text-align: right;\">        V2</th><th style=\"text-align: right;\">        V3</th><th style=\"text-align: right;\">       V4</th><th style=\"text-align: right;\">        V5</th><th style=\"text-align: right;\">        V6</th><th style=\"text-align: right;\">       V7</th><th style=\"text-align: right;\">        V8</th><th style=\"text-align: right;\">       V9</th><th style=\"text-align: right;\">       V10</th><th style=\"text-align: right;\">      V11</th><th style=\"text-align: right;\">       V12</th><th style=\"text-align: right;\">      V13</th><th style=\"text-align: right;\">       V14</th><th style=\"text-align: right;\">       V15</th><th style=\"text-align: right;\">      V16</th><th style=\"text-align: right;\">        V17</th><th style=\"text-align: right;\">       V18</th><th style=\"text-align: right;\">       V19</th><th style=\"text-align: right;\">       V20</th><th style=\"text-align: right;\">       V21</th><th style=\"text-align: right;\">       V22</th><th style=\"text-align: right;\">       V23</th><th style=\"text-align: right;\">       V24</th><th style=\"text-align: right;\">      V25</th><th style=\"text-align: right;\">       V26</th><th style=\"text-align: right;\">       V27</th><th style=\"text-align: right;\">        V28</th><th style=\"text-align: right;\">  Amount</th><th style=\"text-align: right;\">  Class</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">-1.35981 </td><td style=\"text-align: right;\">-0.0727812</td><td style=\"text-align: right;\"> 2.53635  </td><td style=\"text-align: right;\"> 1.37816 </td><td style=\"text-align: right;\">-0.338321 </td><td style=\"text-align: right;\"> 0.462388 </td><td style=\"text-align: right;\"> 0.239599</td><td style=\"text-align: right;\"> 0.0986979</td><td style=\"text-align: right;\"> 0.363787</td><td style=\"text-align: right;\"> 0.0907942</td><td style=\"text-align: right;\">-0.5516  </td><td style=\"text-align: right;\">-0.617801 </td><td style=\"text-align: right;\">-0.99139 </td><td style=\"text-align: right;\">-0.311169 </td><td style=\"text-align: right;\"> 1.46818  </td><td style=\"text-align: right;\">-0.470401</td><td style=\"text-align: right;\"> 0.207971  </td><td style=\"text-align: right;\"> 0.0257906</td><td style=\"text-align: right;\"> 0.403993 </td><td style=\"text-align: right;\"> 0.251412 </td><td style=\"text-align: right;\">-0.0183068</td><td style=\"text-align: right;\"> 0.277838 </td><td style=\"text-align: right;\">-0.110474 </td><td style=\"text-align: right;\"> 0.0669281</td><td style=\"text-align: right;\"> 0.128539</td><td style=\"text-align: right;\">-0.189115 </td><td style=\"text-align: right;\"> 0.133558 </td><td style=\"text-align: right;\">-0.0210531 </td><td style=\"text-align: right;\">  149.62</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\"> 1.19186 </td><td style=\"text-align: right;\"> 0.266151 </td><td style=\"text-align: right;\"> 0.16648  </td><td style=\"text-align: right;\"> 0.448154</td><td style=\"text-align: right;\"> 0.0600176</td><td style=\"text-align: right;\">-0.0823608</td><td style=\"text-align: right;\">-0.078803</td><td style=\"text-align: right;\"> 0.0851017</td><td style=\"text-align: right;\">-0.255425</td><td style=\"text-align: right;\">-0.166974 </td><td style=\"text-align: right;\"> 1.61273 </td><td style=\"text-align: right;\"> 1.06524  </td><td style=\"text-align: right;\"> 0.489095</td><td style=\"text-align: right;\">-0.143772 </td><td style=\"text-align: right;\"> 0.635558 </td><td style=\"text-align: right;\"> 0.463917</td><td style=\"text-align: right;\">-0.114805  </td><td style=\"text-align: right;\">-0.183361 </td><td style=\"text-align: right;\">-0.145783 </td><td style=\"text-align: right;\">-0.0690831</td><td style=\"text-align: right;\">-0.225775 </td><td style=\"text-align: right;\">-0.638672 </td><td style=\"text-align: right;\"> 0.101288 </td><td style=\"text-align: right;\">-0.339846 </td><td style=\"text-align: right;\"> 0.16717 </td><td style=\"text-align: right;\"> 0.125895 </td><td style=\"text-align: right;\">-0.0089831</td><td style=\"text-align: right;\"> 0.0147242 </td><td style=\"text-align: right;\">    2.69</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">-1.35835 </td><td style=\"text-align: right;\">-1.34016  </td><td style=\"text-align: right;\"> 1.77321  </td><td style=\"text-align: right;\"> 0.37978 </td><td style=\"text-align: right;\">-0.503198 </td><td style=\"text-align: right;\"> 1.8005   </td><td style=\"text-align: right;\"> 0.791461</td><td style=\"text-align: right;\"> 0.247676 </td><td style=\"text-align: right;\">-1.51465 </td><td style=\"text-align: right;\"> 0.207643 </td><td style=\"text-align: right;\"> 0.624501</td><td style=\"text-align: right;\"> 0.0660837</td><td style=\"text-align: right;\"> 0.717293</td><td style=\"text-align: right;\">-0.165946 </td><td style=\"text-align: right;\"> 2.34586  </td><td style=\"text-align: right;\">-2.89008 </td><td style=\"text-align: right;\"> 1.10997   </td><td style=\"text-align: right;\">-0.121359 </td><td style=\"text-align: right;\">-2.26186  </td><td style=\"text-align: right;\"> 0.52498  </td><td style=\"text-align: right;\"> 0.247998 </td><td style=\"text-align: right;\"> 0.771679 </td><td style=\"text-align: right;\"> 0.909412 </td><td style=\"text-align: right;\">-0.689281 </td><td style=\"text-align: right;\">-0.327642</td><td style=\"text-align: right;\">-0.139097 </td><td style=\"text-align: right;\">-0.0553528</td><td style=\"text-align: right;\">-0.0597518 </td><td style=\"text-align: right;\">  378.66</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">-0.966272</td><td style=\"text-align: right;\">-0.185226 </td><td style=\"text-align: right;\"> 1.79299  </td><td style=\"text-align: right;\">-0.863291</td><td style=\"text-align: right;\">-0.0103089</td><td style=\"text-align: right;\"> 1.2472   </td><td style=\"text-align: right;\"> 0.237609</td><td style=\"text-align: right;\"> 0.377436 </td><td style=\"text-align: right;\">-1.38702 </td><td style=\"text-align: right;\">-0.0549519</td><td style=\"text-align: right;\">-0.226487</td><td style=\"text-align: right;\"> 0.178228 </td><td style=\"text-align: right;\"> 0.507757</td><td style=\"text-align: right;\">-0.287924 </td><td style=\"text-align: right;\">-0.631418 </td><td style=\"text-align: right;\">-1.05965 </td><td style=\"text-align: right;\">-0.684093  </td><td style=\"text-align: right;\"> 1.96578  </td><td style=\"text-align: right;\">-1.23262  </td><td style=\"text-align: right;\">-0.208038 </td><td style=\"text-align: right;\">-0.1083   </td><td style=\"text-align: right;\"> 0.0052736</td><td style=\"text-align: right;\">-0.190321 </td><td style=\"text-align: right;\">-1.17558  </td><td style=\"text-align: right;\"> 0.647376</td><td style=\"text-align: right;\">-0.221929 </td><td style=\"text-align: right;\"> 0.0627228</td><td style=\"text-align: right;\"> 0.0614576 </td><td style=\"text-align: right;\">  123.5 </td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">-1.15823 </td><td style=\"text-align: right;\"> 0.877737 </td><td style=\"text-align: right;\"> 1.54872  </td><td style=\"text-align: right;\"> 0.403034</td><td style=\"text-align: right;\">-0.407193 </td><td style=\"text-align: right;\"> 0.0959215</td><td style=\"text-align: right;\"> 0.592941</td><td style=\"text-align: right;\">-0.270533 </td><td style=\"text-align: right;\"> 0.817739</td><td style=\"text-align: right;\"> 0.753074 </td><td style=\"text-align: right;\">-0.822843</td><td style=\"text-align: right;\"> 0.538196 </td><td style=\"text-align: right;\"> 1.34585 </td><td style=\"text-align: right;\">-1.11967  </td><td style=\"text-align: right;\"> 0.175121 </td><td style=\"text-align: right;\">-0.451449</td><td style=\"text-align: right;\">-0.237033  </td><td style=\"text-align: right;\">-0.0381948</td><td style=\"text-align: right;\"> 0.803487 </td><td style=\"text-align: right;\"> 0.408542 </td><td style=\"text-align: right;\">-0.0094307</td><td style=\"text-align: right;\"> 0.798278 </td><td style=\"text-align: right;\">-0.137458 </td><td style=\"text-align: right;\"> 0.141267 </td><td style=\"text-align: right;\">-0.20601 </td><td style=\"text-align: right;\"> 0.502292 </td><td style=\"text-align: right;\"> 0.219422 </td><td style=\"text-align: right;\"> 0.215153  </td><td style=\"text-align: right;\">   69.99</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">-0.425966</td><td style=\"text-align: right;\"> 0.960523 </td><td style=\"text-align: right;\"> 1.14111  </td><td style=\"text-align: right;\">-0.168252</td><td style=\"text-align: right;\"> 0.420987 </td><td style=\"text-align: right;\">-0.0297276</td><td style=\"text-align: right;\"> 0.476201</td><td style=\"text-align: right;\"> 0.260314 </td><td style=\"text-align: right;\">-0.568671</td><td style=\"text-align: right;\">-0.371407 </td><td style=\"text-align: right;\"> 1.34126 </td><td style=\"text-align: right;\"> 0.359894 </td><td style=\"text-align: right;\">-0.358091</td><td style=\"text-align: right;\">-0.137134 </td><td style=\"text-align: right;\"> 0.517617 </td><td style=\"text-align: right;\"> 0.401726</td><td style=\"text-align: right;\">-0.0581328 </td><td style=\"text-align: right;\"> 0.0686531</td><td style=\"text-align: right;\">-0.0331938</td><td style=\"text-align: right;\"> 0.0849677</td><td style=\"text-align: right;\">-0.208254 </td><td style=\"text-align: right;\">-0.559825 </td><td style=\"text-align: right;\">-0.0263977</td><td style=\"text-align: right;\">-0.371427 </td><td style=\"text-align: right;\">-0.232794</td><td style=\"text-align: right;\"> 0.105915 </td><td style=\"text-align: right;\"> 0.253844 </td><td style=\"text-align: right;\"> 0.0810803 </td><td style=\"text-align: right;\">    3.67</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\"> 1.22966 </td><td style=\"text-align: right;\"> 0.141004 </td><td style=\"text-align: right;\"> 0.0453708</td><td style=\"text-align: right;\"> 1.20261 </td><td style=\"text-align: right;\"> 0.191881 </td><td style=\"text-align: right;\"> 0.272708 </td><td style=\"text-align: right;\">-0.005159</td><td style=\"text-align: right;\"> 0.0812129</td><td style=\"text-align: right;\"> 0.46496 </td><td style=\"text-align: right;\">-0.0992543</td><td style=\"text-align: right;\">-1.41691 </td><td style=\"text-align: right;\">-0.153826 </td><td style=\"text-align: right;\">-0.751063</td><td style=\"text-align: right;\"> 0.167372 </td><td style=\"text-align: right;\"> 0.0501436</td><td style=\"text-align: right;\">-0.443587</td><td style=\"text-align: right;\"> 0.00282051</td><td style=\"text-align: right;\">-0.611987 </td><td style=\"text-align: right;\">-0.045575 </td><td style=\"text-align: right;\">-0.219633 </td><td style=\"text-align: right;\">-0.167716 </td><td style=\"text-align: right;\">-0.27071  </td><td style=\"text-align: right;\">-0.154104 </td><td style=\"text-align: right;\">-0.780055 </td><td style=\"text-align: right;\"> 0.750137</td><td style=\"text-align: right;\">-0.257237 </td><td style=\"text-align: right;\"> 0.0345074</td><td style=\"text-align: right;\"> 0.00516777</td><td style=\"text-align: right;\">    4.99</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">-0.644269</td><td style=\"text-align: right;\"> 1.41796  </td><td style=\"text-align: right;\"> 1.07438  </td><td style=\"text-align: right;\">-0.492199</td><td style=\"text-align: right;\"> 0.948934 </td><td style=\"text-align: right;\"> 0.428118 </td><td style=\"text-align: right;\"> 1.12063 </td><td style=\"text-align: right;\">-3.80786  </td><td style=\"text-align: right;\"> 0.615375</td><td style=\"text-align: right;\"> 1.24938  </td><td style=\"text-align: right;\">-0.619468</td><td style=\"text-align: right;\"> 0.291474 </td><td style=\"text-align: right;\"> 1.75796 </td><td style=\"text-align: right;\">-1.32387  </td><td style=\"text-align: right;\"> 0.686133 </td><td style=\"text-align: right;\">-0.076127</td><td style=\"text-align: right;\">-1.22213   </td><td style=\"text-align: right;\">-0.358222 </td><td style=\"text-align: right;\"> 0.324505 </td><td style=\"text-align: right;\">-0.156742 </td><td style=\"text-align: right;\"> 1.94347  </td><td style=\"text-align: right;\">-1.01545  </td><td style=\"text-align: right;\"> 0.0575035</td><td style=\"text-align: right;\">-0.649709 </td><td style=\"text-align: right;\">-0.415267</td><td style=\"text-align: right;\">-0.0516343</td><td style=\"text-align: right;\">-1.20692  </td><td style=\"text-align: right;\">-1.08534   </td><td style=\"text-align: right;\">   40.8 </td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">-0.894286</td><td style=\"text-align: right;\"> 0.286157 </td><td style=\"text-align: right;\">-0.113192 </td><td style=\"text-align: right;\">-0.271526</td><td style=\"text-align: right;\"> 2.6696   </td><td style=\"text-align: right;\"> 3.72182  </td><td style=\"text-align: right;\"> 0.370145</td><td style=\"text-align: right;\"> 0.851084 </td><td style=\"text-align: right;\">-0.392048</td><td style=\"text-align: right;\">-0.41043  </td><td style=\"text-align: right;\">-0.705117</td><td style=\"text-align: right;\">-0.110452 </td><td style=\"text-align: right;\">-0.286254</td><td style=\"text-align: right;\"> 0.0743554</td><td style=\"text-align: right;\">-0.328783 </td><td style=\"text-align: right;\">-0.210077</td><td style=\"text-align: right;\">-0.499768  </td><td style=\"text-align: right;\"> 0.118765 </td><td style=\"text-align: right;\"> 0.570328 </td><td style=\"text-align: right;\"> 0.0527357</td><td style=\"text-align: right;\">-0.0734251</td><td style=\"text-align: right;\">-0.268092 </td><td style=\"text-align: right;\">-0.204233 </td><td style=\"text-align: right;\"> 1.01159  </td><td style=\"text-align: right;\"> 0.373205</td><td style=\"text-align: right;\">-0.384157 </td><td style=\"text-align: right;\"> 0.0117474</td><td style=\"text-align: right;\"> 0.142404  </td><td style=\"text-align: right;\">   93.2 </td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">-0.338262</td><td style=\"text-align: right;\"> 1.11959  </td><td style=\"text-align: right;\"> 1.04437  </td><td style=\"text-align: right;\">-0.222187</td><td style=\"text-align: right;\"> 0.499361 </td><td style=\"text-align: right;\">-0.246761 </td><td style=\"text-align: right;\"> 0.651583</td><td style=\"text-align: right;\"> 0.0695386</td><td style=\"text-align: right;\">-0.736727</td><td style=\"text-align: right;\">-0.366846 </td><td style=\"text-align: right;\"> 1.01761 </td><td style=\"text-align: right;\"> 0.83639  </td><td style=\"text-align: right;\"> 1.00684 </td><td style=\"text-align: right;\">-0.443523 </td><td style=\"text-align: right;\"> 0.150219 </td><td style=\"text-align: right;\"> 0.739453</td><td style=\"text-align: right;\">-0.54098   </td><td style=\"text-align: right;\"> 0.476677 </td><td style=\"text-align: right;\"> 0.451773 </td><td style=\"text-align: right;\"> 0.203711 </td><td style=\"text-align: right;\">-0.246914 </td><td style=\"text-align: right;\">-0.633753 </td><td style=\"text-align: right;\">-0.120794 </td><td style=\"text-align: right;\">-0.38505  </td><td style=\"text-align: right;\">-0.069733</td><td style=\"text-align: right;\"> 0.0941988</td><td style=\"text-align: right;\"> 0.246219 </td><td style=\"text-align: right;\"> 0.0830756 </td><td style=\"text-align: right;\">    3.68</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.columns\n",
    "C=data['Class']\n",
    "x.remove('Class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "fraud_dl =H2OAutoEncoderEstimator(hidden = [10,10], epochs = 10, activation='Tanh',seed=SEED)\n",
    "fraud_anon = fraud_dl.train(x=x,training_frame=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OAutoEncoderEstimator :  Deep Learning\n",
      "Model Key:  DeepLearning_model_python_1583294950982_1\n",
      "\n",
      "\n",
      "Status of Neuron Layers: auto-encoder, gaussian distribution, Quadratic loss, 750 weights/biases, 17.5 KB, 2,900,834 training samples, mini-batch size 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>units</th>\n",
       "      <th>type</th>\n",
       "      <th>dropout</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>mean_rate</th>\n",
       "      <th>rate_rms</th>\n",
       "      <th>momentum</th>\n",
       "      <th>mean_weight</th>\n",
       "      <th>weight_rms</th>\n",
       "      <th>mean_bias</th>\n",
       "      <th>bias_rms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>Input</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.876834</td>\n",
       "      <td>0.145978</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00445448</td>\n",
       "      <td>0.781143</td>\n",
       "      <td>-0.0221117</td>\n",
       "      <td>0.18471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125431</td>\n",
       "      <td>0.0421103</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0312271</td>\n",
       "      <td>0.204813</td>\n",
       "      <td>-0.0170112</td>\n",
       "      <td>0.0482499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>Tanh</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062722</td>\n",
       "      <td>0.0326231</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00303805</td>\n",
       "      <td>0.0945551</td>\n",
       "      <td>-0.00527475</td>\n",
       "      <td>0.0521868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     layer  units   type dropout l1 l2 mean_rate   rate_rms momentum  \\\n",
       "0        1     30  Input       0                                       \n",
       "1        2     10   Tanh       0  0  0  0.876834   0.145978        0   \n",
       "2        3     10   Tanh       0  0  0  0.125431  0.0421103        0   \n",
       "3        4     30   Tanh          0  0  0.062722  0.0326231        0   \n",
       "\n",
       "  mean_weight weight_rms   mean_bias   bias_rms  \n",
       "0                                                \n",
       "1 -0.00445448   0.781143  -0.0221117    0.18471  \n",
       "2   0.0312271   0.204813  -0.0170112  0.0482499  \n",
       "3  0.00303805  0.0945551 -0.00527475  0.0521868  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsAutoEncoder: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.00039096426497056073\n",
      "RMSE: 0.01977281631357963\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>training_speed</th>\n",
       "      <th>epochs</th>\n",
       "      <th>iterations</th>\n",
       "      <th>samples</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-03 22:09:16</td>\n",
       "      <td>1.091 sec</td>\n",
       "      <td>0.00000 obs/sec</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090335</td>\n",
       "      <td>0.008160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-03 22:09:22</td>\n",
       "      <td>6.324 sec</td>\n",
       "      <td>191820 obs/sec</td>\n",
       "      <td>3.513032</td>\n",
       "      <td>10</td>\n",
       "      <td>1000536.0</td>\n",
       "      <td>0.024011</td>\n",
       "      <td>0.000577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-03 22:09:27</td>\n",
       "      <td>12.462 sec</td>\n",
       "      <td>181747 obs/sec</td>\n",
       "      <td>6.670514</td>\n",
       "      <td>19</td>\n",
       "      <td>1899809.0</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.000555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2020-03-03 22:09:33</td>\n",
       "      <td>17.742 sec</td>\n",
       "      <td>184507 obs/sec</td>\n",
       "      <td>10.185262</td>\n",
       "      <td>29</td>\n",
       "      <td>2900834.0</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>0.000391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    duration   training_speed     epochs  iterations  \\\n",
       "0    2020-03-03 22:09:16   1.091 sec  0.00000 obs/sec   0.000000           0   \n",
       "1    2020-03-03 22:09:22   6.324 sec   191820 obs/sec   3.513032          10   \n",
       "2    2020-03-03 22:09:27  12.462 sec   181747 obs/sec   6.670514          19   \n",
       "3    2020-03-03 22:09:33  17.742 sec   184507 obs/sec  10.185262          29   \n",
       "\n",
       "     samples  training_rmse  training_mse  \n",
       "0        0.0       0.090335      0.008160  \n",
       "1  1000536.0       0.024011      0.000577  \n",
       "2  1899809.0       0.023558      0.000555  \n",
       "3  2900834.0       0.019773      0.000391  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V18</td>\n",
       "      <td>0.861280</td>\n",
       "      <td>0.861280</td>\n",
       "      <td>0.095134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V19</td>\n",
       "      <td>0.840541</td>\n",
       "      <td>0.840541</td>\n",
       "      <td>0.092843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V11</td>\n",
       "      <td>0.819380</td>\n",
       "      <td>0.819380</td>\n",
       "      <td>0.090506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V15</td>\n",
       "      <td>0.736666</td>\n",
       "      <td>0.736666</td>\n",
       "      <td>0.081370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>V26</td>\n",
       "      <td>0.732399</td>\n",
       "      <td>0.732399</td>\n",
       "      <td>0.080898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V24</td>\n",
       "      <td>0.697082</td>\n",
       "      <td>0.697082</td>\n",
       "      <td>0.076997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>V13</td>\n",
       "      <td>0.673406</td>\n",
       "      <td>0.673406</td>\n",
       "      <td>0.074382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>V4</td>\n",
       "      <td>0.649554</td>\n",
       "      <td>0.649554</td>\n",
       "      <td>0.071748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Time</td>\n",
       "      <td>0.564765</td>\n",
       "      <td>0.564765</td>\n",
       "      <td>0.062382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>V12</td>\n",
       "      <td>0.326680</td>\n",
       "      <td>0.326680</td>\n",
       "      <td>0.036084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>V14</td>\n",
       "      <td>0.133143</td>\n",
       "      <td>0.133143</td>\n",
       "      <td>0.014706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>V5</td>\n",
       "      <td>0.121940</td>\n",
       "      <td>0.121940</td>\n",
       "      <td>0.013469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>V10</td>\n",
       "      <td>0.117312</td>\n",
       "      <td>0.117312</td>\n",
       "      <td>0.012958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>V7</td>\n",
       "      <td>0.098422</td>\n",
       "      <td>0.098422</td>\n",
       "      <td>0.010871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>V3</td>\n",
       "      <td>0.097963</td>\n",
       "      <td>0.097963</td>\n",
       "      <td>0.010821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>V17</td>\n",
       "      <td>0.077767</td>\n",
       "      <td>0.077767</td>\n",
       "      <td>0.008590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>V22</td>\n",
       "      <td>0.059537</td>\n",
       "      <td>0.059537</td>\n",
       "      <td>0.006576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>V1</td>\n",
       "      <td>0.052949</td>\n",
       "      <td>0.052949</td>\n",
       "      <td>0.005849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>V25</td>\n",
       "      <td>0.050158</td>\n",
       "      <td>0.050158</td>\n",
       "      <td>0.005540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable  relative_importance  scaled_importance  percentage\n",
       "0        V9             1.000000           1.000000    0.110457\n",
       "1       V18             0.861280           0.861280    0.095134\n",
       "2       V19             0.840541           0.840541    0.092843\n",
       "3       V11             0.819380           0.819380    0.090506\n",
       "4       V15             0.736666           0.736666    0.081370\n",
       "5       V26             0.732399           0.732399    0.080898\n",
       "6       V24             0.697082           0.697082    0.076997\n",
       "7       V13             0.673406           0.673406    0.074382\n",
       "8        V4             0.649554           0.649554    0.071748\n",
       "9      Time             0.564765           0.564765    0.062382\n",
       "10      V12             0.326680           0.326680    0.036084\n",
       "11      V14             0.133143           0.133143    0.014706\n",
       "12       V5             0.121940           0.121940    0.013469\n",
       "13      V10             0.117312           0.117312    0.012958\n",
       "14       V7             0.098422           0.098422    0.010871\n",
       "15       V3             0.097963           0.097963    0.010821\n",
       "16      V17             0.077767           0.077767    0.008590\n",
       "17      V22             0.059537           0.059537    0.006576\n",
       "18       V1             0.052949           0.052949    0.005849\n",
       "19      V25             0.050158           0.050158    0.005540"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = fraud_dl.score_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dd151de5c8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "# plot training logloss and auc\n",
    "sh.plot(x='epochs', y = ['training_rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "err=(fraud_dl.anomaly(data)).cbind(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  Reconstruction.MSE</th><th style=\"text-align: right;\">  Class</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">         0.000122688</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0.000101776</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0.000598604</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0.00011135 </td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0.000262742</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         4.23423e-05</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         6.60165e-05</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0.000398629</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         9.75006e-05</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         8.28065e-05</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "err=err.as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "err=tf.cast(err.values, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00038484595"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(err[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[1.        , 0.45944107],\n",
       "       [0.45944107, 0.9999914 ]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find correlation between reconstruction error and fraud flag\n",
    "\n",
    "tfp.stats.correlation(\n",
    "    err, y=None, sample_axis=0, event_axis=-1, keepdims=False, name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-517.10144 ,    9.424312], dtype=float32)>,\n",
       " <tf.Tensor: shape=(284807,), dtype=float32, numpy=\n",
       " array([-0.06344198, -0.05262848, -0.30953917, ..., -0.23271678,\n",
       "        -0.5250792 , -0.20824815], dtype=float32)>,\n",
       " <tf.Tensor: shape=(), dtype=bool, numpy=False>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=1>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit a glm to access if reconstruction error is a predictor of fraud\n",
    "\n",
    "tfp.glm.fit(\n",
    "    model_matrix=err, response=err[:,1], model=tfp.glm.Bernoulli(), model_coefficients_start=None,\n",
    "    predicted_linear_response_start=None, l2_regularizer=None, dispersion=None,\n",
    "    offset=None, convergence_criteria_fn=None, learning_rate=None,\n",
    "    fast_unsafe_numerics=True, maximum_iterations=1,\n",
    "    l2_regularization_penalty_factor=None, name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.9999218>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def logit2prob(logit):\n",
    "  odds = tf.exp(logit)\n",
    "  prob = odds / (1.000 + odds)\n",
    "  return(prob)\n",
    "logit2prob(9.456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.scale(center=True,scale=True)\n",
    "data=np.array(data[:,x].as_data_frame())\n",
    "data=tf.keras.utils.normalize(\n",
    "    data, axis=-1, order=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael Lanier\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Deprecated, use ``h2o.cluster().shutdown()``.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_9506 closed.\n"
     ]
    }
   ],
   "source": [
    "h2o.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 10\n",
    "batch_size = 128\n",
    "input_dim = data.shape[1] #num of columns, 30\n",
    "encoding_dim = 10\n",
    "hidden_dim = 10 \n",
    "\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\",kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None))(input_layer)\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\",kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None))(encoder)\n",
    "\n",
    "decoder = Dense(input_dim, activation='tanh',kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None))(encoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logdir=\"C:\\\\Users\\\\Michael Lanier\\\\notebook\\\\logs\"\n",
    "#!mkdir 'C:\\\\Users\\\\Michael Lanier\\\\notebook\\\\logs\\\\train'\n",
    "#!tensorboard --logdir \"C:\\Users\\Michael Lanier\\notebook\\logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284807 samples\n",
      "Epoch 1/10\n",
      "283008/284807 [============================>.] - ETA: 8:20 - loss: 0.0333 - mean_absolute_error: 0.139 - ETA: 33s - loss: 0.0332 - mean_absolute_error: 0.139 - ETA: 19s - loss: 0.0330 - mean_absolute_error: 0.13 - ETA: 15s - loss: 0.0328 - mean_absolute_error: 0.13 - ETA: 12s - loss: 0.0324 - mean_absolute_error: 0.13 - ETA: 11s - loss: 0.0318 - mean_absolute_error: 0.13 - ETA: 10s - loss: 0.0311 - mean_absolute_error: 0.13 - ETA: 9s - loss: 0.0304 - mean_absolute_error: 0.1323 - ETA: 9s - loss: 0.0297 - mean_absolute_error: 0.130 - ETA: 8s - loss: 0.0291 - mean_absolute_error: 0.129 - ETA: 8s - loss: 0.0284 - mean_absolute_error: 0.127 - ETA: 8s - loss: 0.0279 - mean_absolute_error: 0.126 - ETA: 7s - loss: 0.0273 - mean_absolute_error: 0.124 - ETA: 7s - loss: 0.0268 - mean_absolute_error: 0.123 - ETA: 7s - loss: 0.0262 - mean_absolute_error: 0.121 - ETA: 6s - loss: 0.0257 - mean_absolute_error: 0.120 - ETA: 6s - loss: 0.0253 - mean_absolute_error: 0.119 - ETA: 6s - loss: 0.0249 - mean_absolute_error: 0.118 - ETA: 6s - loss: 0.0245 - mean_absolute_error: 0.117 - ETA: 6s - loss: 0.0242 - mean_absolute_error: 0.115 - ETA: 6s - loss: 0.0238 - mean_absolute_error: 0.114 - ETA: 5s - loss: 0.0235 - mean_absolute_error: 0.114 - ETA: 5s - loss: 0.0232 - mean_absolute_error: 0.113 - ETA: 5s - loss: 0.0229 - mean_absolute_error: 0.112 - ETA: 5s - loss: 0.0226 - mean_absolute_error: 0.111 - ETA: 5s - loss: 0.0224 - mean_absolute_error: 0.110 - ETA: 5s - loss: 0.0221 - mean_absolute_error: 0.109 - ETA: 5s - loss: 0.0219 - mean_absolute_error: 0.109 - ETA: 5s - loss: 0.0216 - mean_absolute_error: 0.108 - ETA: 5s - loss: 0.0214 - mean_absolute_error: 0.107 - ETA: 4s - loss: 0.0212 - mean_absolute_error: 0.107 - ETA: 4s - loss: 0.0210 - mean_absolute_error: 0.106 - ETA: 4s - loss: 0.0208 - mean_absolute_error: 0.105 - ETA: 4s - loss: 0.0206 - mean_absolute_error: 0.105 - ETA: 4s - loss: 0.0205 - mean_absolute_error: 0.104 - ETA: 4s - loss: 0.0203 - mean_absolute_error: 0.104 - ETA: 4s - loss: 0.0201 - mean_absolute_error: 0.103 - ETA: 4s - loss: 0.0199 - mean_absolute_error: 0.103 - ETA: 4s - loss: 0.0198 - mean_absolute_error: 0.102 - ETA: 4s - loss: 0.0196 - mean_absolute_error: 0.102 - ETA: 4s - loss: 0.0195 - mean_absolute_error: 0.101 - ETA: 4s - loss: 0.0193 - mean_absolute_error: 0.101 - ETA: 4s - loss: 0.0192 - mean_absolute_error: 0.100 - ETA: 3s - loss: 0.0191 - mean_absolute_error: 0.100 - ETA: 3s - loss: 0.0190 - mean_absolute_error: 0.099 - ETA: 3s - loss: 0.0189 - mean_absolute_error: 0.099 - ETA: 3s - loss: 0.0188 - mean_absolute_error: 0.099 - ETA: 3s - loss: 0.0187 - mean_absolute_error: 0.098 - ETA: 3s - loss: 0.0186 - mean_absolute_error: 0.098 - ETA: 3s - loss: 0.0185 - mean_absolute_error: 0.098 - ETA: 3s - loss: 0.0184 - mean_absolute_error: 0.097 - ETA: 3s - loss: 0.0183 - mean_absolute_error: 0.097 - ETA: 3s - loss: 0.0182 - mean_absolute_error: 0.097 - ETA: 3s - loss: 0.0181 - mean_absolute_error: 0.096 - ETA: 3s - loss: 0.0181 - mean_absolute_error: 0.096 - ETA: 3s - loss: 0.0180 - mean_absolute_error: 0.096 - ETA: 3s - loss: 0.0179 - mean_absolute_error: 0.096 - ETA: 3s - loss: 0.0179 - mean_absolute_error: 0.095 - ETA: 3s - loss: 0.0178 - mean_absolute_error: 0.095 - ETA: 2s - loss: 0.0177 - mean_absolute_error: 0.095 - ETA: 2s - loss: 0.0177 - mean_absolute_error: 0.095 - ETA: 2s - loss: 0.0176 - mean_absolute_error: 0.094 - ETA: 2s - loss: 0.0175 - mean_absolute_error: 0.094 - ETA: 2s - loss: 0.0175 - mean_absolute_error: 0.094 - ETA: 2s - loss: 0.0174 - mean_absolute_error: 0.094 - ETA: 2s - loss: 0.0174 - mean_absolute_error: 0.094 - ETA: 2s - loss: 0.0173 - mean_absolute_error: 0.093 - ETA: 2s - loss: 0.0173 - mean_absolute_error: 0.093 - ETA: 2s - loss: 0.0172 - mean_absolute_error: 0.093 - ETA: 2s - loss: 0.0172 - mean_absolute_error: 0.093 - ETA: 2s - loss: 0.0171 - mean_absolute_error: 0.093 - ETA: 2s - loss: 0.0171 - mean_absolute_error: 0.093 - ETA: 2s - loss: 0.0170 - mean_absolute_error: 0.092 - ETA: 2s - loss: 0.0170 - mean_absolute_error: 0.092 - ETA: 2s - loss: 0.0170 - mean_absolute_error: 0.092 - ETA: 2s - loss: 0.0169 - mean_absolute_error: 0.092 - ETA: 2s - loss: 0.0169 - mean_absolute_error: 0.092 - ETA: 1s - loss: 0.0169 - mean_absolute_error: 0.092 - ETA: 1s - loss: 0.0168 - mean_absolute_error: 0.092 - ETA: 1s - loss: 0.0168 - mean_absolute_error: 0.091 - ETA: 1s - loss: 0.0167 - mean_absolute_error: 0.091 - ETA: 1s - loss: 0.0167 - mean_absolute_error: 0.091 - ETA: 1s - loss: 0.0167 - mean_absolute_error: 0.091 - ETA: 1s - loss: 0.0166 - mean_absolute_error: 0.091 - ETA: 1s - loss: 0.0166 - mean_absolute_error: 0.091 - ETA: 1s - loss: 0.0166 - mean_absolute_error: 0.091 - ETA: 1s - loss: 0.0166 - mean_absolute_error: 0.091 - ETA: 1s - loss: 0.0165 - mean_absolute_error: 0.090 - ETA: 1s - loss: 0.0165 - mean_absolute_error: 0.090 - ETA: 1s - loss: 0.0165 - mean_absolute_error: 0.090 - ETA: 1s - loss: 0.0164 - mean_absolute_error: 0.090 - ETA: 1s - loss: 0.0164 - mean_absolute_error: 0.090 - ETA: 1s - loss: 0.0164 - mean_absolute_error: 0.090 - ETA: 1s - loss: 0.0163 - mean_absolute_error: 0.090 - ETA: 1s - loss: 0.0163 - mean_absolute_error: 0.090 - ETA: 1s - loss: 0.0163 - mean_absolute_error: 0.090 - ETA: 0s - loss: 0.0163 - mean_absolute_error: 0.090 - ETA: 0s - loss: 0.0162 - mean_absolute_error: 0.089 - ETA: 0s - loss: 0.0162 - mean_absolute_error: 0.089 - ETA: 0s - loss: 0.0162 - mean_absolute_error: 0.089 - ETA: 0s - loss: 0.0162 - mean_absolute_error: 0.089 - ETA: 0s - loss: 0.0162 - mean_absolute_error: 0.089 - ETA: 0s - loss: 0.0161 - mean_absolute_error: 0.089 - ETA: 0s - loss: 0.0161 - mean_absolute_error: 0.089 - ETA: 0s - loss: 0.0161 - mean_absolute_error: 0.089 - ETA: 0s - loss: 0.0161 - mean_absolute_error: 0.089 - ETA: 0s - loss: 0.0160 - mean_absolute_error: 0.089 - ETA: 0s - loss: 0.0160 - mean_absolute_error: 0.089 - ETA: 0s - loss: 0.0160 - mean_absolute_error: 0.089 - ETA: 0s - loss: 0.0160 - mean_absolute_error: 0.088 - ETA: 0s - loss: 0.0160 - mean_absolute_error: 0.088 - ETA: 0s - loss: 0.0159 - mean_absolute_error: 0.088 - ETA: 0s - loss: 0.0159 - mean_absolute_error: 0.088 - ETA: 0s - loss: 0.0159 - mean_absolute_error: 0.088 - ETA: 0s - loss: 0.0159 - mean_absolute_error: 0.0885\n",
      "Epoch 00001: saving model to autoencoder_fraud.h5\n",
      "284807/284807 [==============================] - 6s 22us/sample - loss: 0.0159 - mean_absolute_error: 0.0885\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283904/284807 [============================>.] - ETA: 8s - loss: 0.0137 - mean_absolute_error: 0.078 - ETA: 6s - loss: 0.0135 - mean_absolute_error: 0.079 - ETA: 6s - loss: 0.0136 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0136 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0136 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0136 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0136 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0136 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0137 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0137 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0137 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0137 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0137 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.0805\n",
      "Epoch 00002: saving model to autoencoder_fraud.h5\n",
      "284807/284807 [==============================] - 6s 22us/sample - loss: 0.0138 - mean_absolute_error: 0.0805\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284288/284807 [============================>.] - ETA: 11s - loss: 0.0123 - mean_absolute_error: 0.07 - ETA: 6s - loss: 0.0139 - mean_absolute_error: 0.0809 - ETA: 6s - loss: 0.0140 - mean_absolute_error: 0.081 - ETA: 6s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 6s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.0804\n",
      "Epoch 00003: saving model to autoencoder_fraud.h5\n",
      "284807/284807 [==============================] - 6s 21us/sample - loss: 0.0138 - mean_absolute_error: 0.0804\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283008/284807 [============================>.] - ETA: 8s - loss: 0.0129 - mean_absolute_error: 0.077 - ETA: 6s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.0802\n",
      "Epoch 00004: saving model to autoencoder_fraud.h5\n",
      "284807/284807 [==============================] - 6s 21us/sample - loss: 0.0138 - mean_absolute_error: 0.0802\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284032/284807 [============================>.] - ETA: 8s - loss: 0.0132 - mean_absolute_error: 0.079 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0137 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.0801\n",
      "Epoch 00005: saving model to autoencoder_fraud.h5\n",
      "284807/284807 [==============================] - 5s 19us/sample - loss: 0.0138 - mean_absolute_error: 0.0801\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282880/284807 [============================>.] - ETA: 8s - loss: 0.0144 - mean_absolute_error: 0.081 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0137 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0137 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.0801\n",
      "Epoch 00006: saving model to autoencoder_fraud.h5\n",
      "284807/284807 [==============================] - 5s 18us/sample - loss: 0.0138 - mean_absolute_error: 0.0801\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284800/284807 [============================>.] - ETA: 6s - loss: 0.0137 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.0801\n",
      "Epoch 00007: saving model to autoencoder_fraud.h5\n",
      "284807/284807 [==============================] - 6s 20us/sample - loss: 0.0138 - mean_absolute_error: 0.0801\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283264/284807 [============================>.] - ETA: 8s - loss: 0.0132 - mean_absolute_error: 0.078 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.0801\n",
      "Epoch 00008: saving model to autoencoder_fraud.h5\n",
      "284807/284807 [==============================] - 5s 18us/sample - loss: 0.0138 - mean_absolute_error: 0.0801\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284544/284807 [============================>.] - ETA: 8s - loss: 0.0150 - mean_absolute_error: 0.083 - ETA: 5s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0139 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 3s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.079 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.0800\n",
      "Epoch 00009: saving model to autoencoder_fraud.h5\n",
      "284807/284807 [==============================] - 5s 19us/sample - loss: 0.0138 - mean_absolute_error: 0.0800\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284032/284807 [============================>.] - ETA: 11s - loss: 0.0138 - mean_absolute_error: 0.08 - ETA: 5s - loss: 0.0140 - mean_absolute_error: 0.0807 - ETA: 5s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 5s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 5s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 5s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 5s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 5s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 5s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 5s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 5s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 5s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 5s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.079 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0137 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 4s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 3s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 2s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 1s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0138 - mean_absolute_error: 0.0801\n",
      "Epoch 00010: saving model to autoencoder_fraud.h5\n",
      "284807/284807 [==============================] - 6s 23us/sample - loss: 0.0138 - mean_absolute_error: 0.0801\n"
     ]
    }
   ],
   "source": [
    "\n",
    "autoencoder.compile(metrics=['mean_absolute_error'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"autoencoder_fraud.h5\",\n",
    "                               #save_best_only=True,\n",
    "                               verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "history = autoencoder.fit(data, data,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.0800\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = autoencoder.evaluate(data, data, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction_error</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.013783</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.008946</td>\n",
       "      <td>0.041494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.005490</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.012841</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.020976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.034662</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction_error          Class\n",
       "count         284807.000000  284807.000000\n",
       "mean               0.013783       0.001727\n",
       "std                0.008946       0.041494\n",
       "min                0.000372       0.000000\n",
       "25%                0.005490       0.000000\n",
       "50%                0.012841       0.000000\n",
       "75%                0.020976       0.000000\n",
       "max                0.034662       1.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_predictions = autoencoder.predict(data)\n",
    "mse = np.mean(np.power(data - data_predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'Reconstruction_error': mse,\n",
    "                        'Class': err[:,1]})\n",
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.47812313, -0.18336764,  0.06216399, ...,  0.0441631 ,\n",
       "         0.04368399, -0.00522644],\n",
       "       [-0.44274208,  0.13033065,  0.03687496, ..., -0.00885831,\n",
       "        -0.00408332, -0.06848453],\n",
       "       [-0.30515006, -0.11340678, -0.00397376, ...,  0.02801088,\n",
       "         0.02643741,  0.01251646],\n",
       "       ...,\n",
       "       [ 0.31389302,  0.19075595, -0.06427637, ..., -0.01194388,\n",
       "        -0.01527938, -0.00965813],\n",
       "       [ 0.16245097, -0.04857536,  0.01268354, ...,  0.00838079,\n",
       "         0.01002526, -0.00740322],\n",
       "       [ 0.37988597, -0.11056438,  0.15161991, ...,  0.06949066,\n",
       "         0.0435469 , -0.0481507 ]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.53016041, -0.18434485, -0.01170339, ...,  0.08786293,\n",
       "        -0.01693606,  0.06504631],\n",
       "       [-0.60603262,  0.18469987,  0.04892252, ..., -0.00675537,\n",
       "         0.01353994, -0.10395297],\n",
       "       [-0.29521237, -0.10254123, -0.12000019, ..., -0.0202771 ,\n",
       "        -0.0267658 ,  0.17161944],\n",
       "       ...,\n",
       "       [ 0.33761922,  0.20151047, -0.03751165, ...,  0.00226935,\n",
       "        -0.0165455 , -0.01682763],\n",
       "       [ 0.2799623 , -0.02093023,  0.05477432, ...,  0.04596843,\n",
       "         0.05399622, -0.05340998],\n",
       "       [ 0.4476601 , -0.07424324, -0.03132392, ..., -0.00163135,\n",
       "         0.01127289,  0.14022427]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013782585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.9999999 , 0.08043329],\n",
       "       [0.08043329, 0.9999914 ]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "err=tf.cast(error_df.values, tf.float32)\n",
    "print(np.average(err[:,0]))\n",
    "\n",
    "tfp.stats.correlation(\n",
    "    err, y=None, sample_axis=0, event_axis=-1, keepdims=False, name=None\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
